"""Train a meta-classifier that combines text and emotion features."""
from __future__ import annotations

import argparse
import time
from pathlib import Path
from typing import List

import joblib
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, f1_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler


FEATURE_CSV = Path("prop_datasets") / "tree_width" / "meta_features.csv"
MODEL_PATH = Path("models") / "meta_classifier.joblib"

EMOTION_FEATURES: List[str] = [
    "mean_anger",
    "mean_disgust",
    "mean_fear",
    "mean_joy",
    "mean_sadness",
    "mean_surprise",
    "mean_neutral",
]
ADDITIONAL_FEATURES = ["entropy", "variance"]


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Train a meta-classifier on propaganda and emotion features")
    parser.add_argument(
        "--features-csv",
        type=Path,
        default=FEATURE_CSV,
        help="Path to the feature CSV generated by build_meta_dataset.py",
    )
    parser.add_argument(
        "--model-out",
        type=Path,
        default=MODEL_PATH,
        help="Location to store the trained meta-classifier pipeline",
    )
    parser.add_argument(
        "--test-size",
        type=float,
        default=0.2,
        help="Hold-out fraction for evaluation",
    )
    parser.add_argument(
        "--random-state",
        type=int,
        default=42,
        help="Random seed for train/test split",
    )
    return parser.parse_args()


def load_features(path: Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(
            f"Feature CSV not found at {path}. Run scripts/build_meta_dataset.py first."
        )
    return pd.read_csv(path)


def train_classifier(table: pd.DataFrame, test_size: float, random_state: int) -> Pipeline:
    feature_columns = ["text_pred", *EMOTION_FEATURES, *ADDITIONAL_FEATURES]
    missing = [col for col in feature_columns if col not in table.columns]
    if missing:
        raise ValueError(f"Missing expected feature columns: {missing}")

    X = table[feature_columns]
    y = table["true_label"].astype(int)

    print(f"Splitting dataset with {len(table)} rows (test_size={test_size})", flush=True)
    split_start = time.perf_counter()
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=test_size,
        random_state=random_state,
        stratify=y,
    )
    print(f"Split complete in {time.perf_counter() - split_start:.2f}s", flush=True)

    pipeline = Pipeline(
        [
            ("scale", StandardScaler()),
            ("clf", LogisticRegression(max_iter=1000, class_weight="balanced")),
        ]
    )

    print("Training logistic regression...", flush=True)
    fit_start = time.perf_counter()
    pipeline.fit(X_train, y_train)
    print(f"Training complete in {time.perf_counter() - fit_start:.2f}s", flush=True)

    print("Evaluating on hold-out set...", flush=True)
    eval_start = time.perf_counter()
    y_pred = pipeline.predict(X_test)
    print(f"Evaluation complete in {time.perf_counter() - eval_start:.2f}s", flush=True)

    print("Evaluation metrics:")
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print(f"F1-score: {f1_score(y_test, y_pred, zero_division=0):.4f}")
    print(classification_report(y_test, y_pred, zero_division=0))

    coef = pipeline.named_steps["clf"].coef_[0]
    print("Model coefficients (feature -> weight):")
    for name, weight in zip(feature_columns, coef):
        print(f"  {name:>12}: {weight:+.4f}")

    return pipeline


def main() -> None:
    args = parse_args()
    overall_start = time.perf_counter()
    print(f"Loading features from {args.features_csv}", flush=True)
    feature_table = load_features(args.features_csv)
    print(f"Loaded feature table with shape {feature_table.shape}", flush=True)

    model = train_classifier(
        feature_table,
        test_size=args.test_size,
        random_state=args.random_state,
    )

    args.model_out.parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(model, args.model_out)
    print(f"Saved meta-classifier to {args.model_out}")
    print(f"Total runtime {time.perf_counter() - overall_start:.2f}s", flush=True)


if __name__ == "__main__":
    main()
